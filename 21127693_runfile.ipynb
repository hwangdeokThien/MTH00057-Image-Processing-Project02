{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb412986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brightness(img, adjustment):\n",
    "    adjusted_img = img.astype(np.int32) + adjustment\n",
    "    adjusted_img = np.clip(adjusted_img, 0, 255)\n",
    "    return adjusted_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b00409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_contrast(img, adjustment):\n",
    "    float_img = img.astype(np.float32) / 255.0\n",
    "    adjusted_channels = np.clip((float_img - 0.5) * adjustment + 0.5, 0, 1)\n",
    "    adjusted_img = (adjusted_channels * 255).astype(np.uint8)\n",
    "    return adjusted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(img, axis='horizontal'):\n",
    "    if axis == 'horizontal':\n",
    "        return img[:, ::-1, :]\n",
    "    else:\n",
    "        return img[::-1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19643dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_scale(img, method='sepia'):\n",
    "    if method == 'grayscale':\n",
    "        adjusted_img = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    else:\n",
    "        sepia_mtx = np.array([[0.393, 0.769, 0.189],\n",
    "                              [0.349, 0.686, 0.168],\n",
    "                              [0.272, 0.534, 0.131]])\n",
    "        adjusted_img = np.clip(np.dot(img, sepia_mtx.T), 0, 255)\n",
    "    \n",
    "    adjusted_img = np.round(adjusted_img).astype(np.uint8)\n",
    "    return adjusted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, kernel):\n",
    "    height, width, _ = img.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    adjusted_img = np.zeros((height, width, 3), dtype=float) \n",
    "    \n",
    "    for i in range(kernel_height//2, height-kernel_height//2-1):\n",
    "        for j in range(kernel_width//2, width-kernel_width//2-1):\n",
    "            window = img[i-kernel_height//2 : i+kernel_height//2+1,j-kernel_width//2 : j+kernel_width//2+1]\n",
    "            adjusted_img[i, j] = [int((window[:,:,k] * kernel).sum()) for k in range(3)]\n",
    "      \n",
    "    adjusted_img = np.clip(adjusted_img, 0, 255)\n",
    "    return adjusted_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, crop_shape):\n",
    "    height, width, _ = img.shape\n",
    "    crop_height, crop_width = crop_shape\n",
    "\n",
    "    start_height = (height - crop_height) // 2\n",
    "    start_width = (width - crop_width) // 2\n",
    "\n",
    "    end_height = start_height + crop_height\n",
    "    end_width = start_width + crop_width\n",
    "\n",
    "    cropped_img = img[start_height:end_height, start_width:end_width]\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_frame_crop(img, center, radius):\n",
    "    yy, xx = np.ogrid[:img.shape[0], :img.shape[1]]\n",
    "    cy, cx = center\n",
    "    \n",
    "    circle_mask = (yy - cy)**2 + (xx - cx)**2 <= radius**2\n",
    "\n",
    "    cropped_img = np.copy(img)\n",
    "    cropped_img[~circle_mask] = 0\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_frame_crop(img, center, major_axis, minor_axis, deg_angle):\n",
    "    yy, xx = np.ogrid[:img.shape[0], :img.shape[1]]\n",
    "    cy, cx = center\n",
    "    rad_angle = np.deg2rad(deg_angle)\n",
    "\n",
    "    ellipse_mask = ((xx - cx) * np.cos(rad_angle) + (yy - cy) * np.sin(rad_angle))**2 / (major_axis**2) + ((xx - cx) * np.sin(rad_angle) - (yy - cy) * np.cos(rad_angle))**2 / (minor_axis**2) <= 1\n",
    "\n",
    "    cropped_img = np.copy(img)\n",
    "    cropped_img[~ellipse_mask] = 0\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_ellipse_frame_crop(img, center, major_axis, minor_axis):\n",
    "    yy, xx = np.ogrid[:img.shape[0], :img.shape[1]]\n",
    "    cy, cx = center\n",
    "    \n",
    "    deg_angle = 45.0\n",
    "    rad_angle = np.deg2rad(deg_angle)\n",
    "    ellipse_mask_1 = ((xx - cx) * np.cos(rad_angle) + (yy - cy) * np.sin(rad_angle))**2 / (major_axis**2) + ((xx - cx) * np.sin(rad_angle) - (yy - cy) * np.cos(rad_angle))**2 / (minor_axis**2) <= 1\n",
    "\n",
    "    deg_angle = 135.0\n",
    "    rad_angle = np.deg2rad(deg_angle)\n",
    "    ellipse_mask_2 = ((xx - cx) * np.cos(rad_angle) + (yy - cy) * np.sin(rad_angle))**2 / (major_axis**2) + ((xx - cx) * np.sin(rad_angle) - (yy - cy) * np.cos(rad_angle))**2 / (minor_axis**2) <= 1\n",
    "    \n",
    "    cropped_img = np.copy(img)\n",
    "    cropped_img[~(ellipse_mask_1 | ellipse_mask_2)] = 0\n",
    "    \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd52a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu_choice():\n",
    "    print('1. Change brightness')\n",
    "    print('2. Change contrast')\n",
    "    print('3. Flip image')\n",
    "    print('4. Convert to grayscale/sepia')\n",
    "    print('5. Blur/sharpen')\n",
    "    print('6. Center crop')\n",
    "    print('7. Circle frame crop')\n",
    "    print('8. Double elip frame crop')\n",
    "    print('0. Change all')\n",
    "    choice = int(input('Your choice: '))\n",
    "    \n",
    "    if choice == 3:\n",
    "        print('\\n1. Flip vertically')\n",
    "        print('2. Flip horizontally')\n",
    "        sub_choice = int(input('Your choice: '))\n",
    "        choice = 9 if sub_choice == 1 else 10\n",
    "    elif choice == 4:\n",
    "        print('\\n1. Grayscale')\n",
    "        print('2. Sepia')\n",
    "        sub_choice = int(input('Your choice: '))\n",
    "        choice = 11 if sub_choice == 1 else 12\n",
    "    elif choice == 5:\n",
    "        print('\\n1. Blur')\n",
    "        print('2. Sharpen')\n",
    "        sub_choice = int(input('Your choice: '))\n",
    "        choice = 13 if sub_choice == 1 else 14\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel for blurring image\n",
    "GAUSSIAN_KERNEL_3 = 1/16 * np.array([[1,2,1],\n",
    "                                     [2,4,2],\n",
    "                                     [1,2,1]])\n",
    "GAUSSIAN_KERNEL_5 = 1/256 * np.array([[1, 4, 6, 4, 1],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [6, 24, 36, 24, 6],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [1, 4, 6, 4, 1]])\n",
    "# kernel for sharpening image\n",
    "SHARPEN_KERNEL_3 = np.array([[0,-1,0],\n",
    "                             [-1,5,-1],\n",
    "                             [0,-1,0]])\n",
    "SHARPEN_KERNEL_5 = -1/256 * np.array([[1, 4, 6, 4, 1],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [6, 24, -476, 24, 6],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [1, 4, 6, 4, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea03423",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    img_path = str(input('Path to image: '))\n",
    "    try:\n",
    "        image = Image.open(img_path)\n",
    "    except:\n",
    "        print('can not open image!')\n",
    "        return\n",
    "    \n",
    "    org_img = np.array(image)\n",
    "    \n",
    "    choice = menu_choice()\n",
    "    processed_images = []\n",
    "    processed_mechanism = []\n",
    "    \n",
    "    if choice == 1 or choice == 0:\n",
    "        adjustment = int(input('Input brightness change: '))\n",
    "        prd_img = change_brightness(org_img.copy(), adjustment)\n",
    "        plt.imsave('output_brightness_change.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Brightness changed')\n",
    "        \n",
    "    if choice == 2 or choice == 0:\n",
    "        adjustment = input('Input contrast change: ')\n",
    "        prd_img = change_contrast(org_img, float(adjustment))\n",
    "        plt.imsave('output_contrast_change.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Contrast changed')\n",
    "    \n",
    "    if choice == 9 or choice == 0:\n",
    "        prd_img = flip(org_img, 'vertical')\n",
    "        plt.imsave('output_vertical_flip.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Vertical flip')\n",
    "    \n",
    "    if choice == 10 or choice == 0:\n",
    "        prd_img = flip(org_img, 'horizontal')\n",
    "        plt.imsave('output_horizontal_flip.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Horizontal flip')\n",
    "    \n",
    "    if choice == 11 or choice == 0:\n",
    "        prd_img = convert_scale(org_img, 'grayscale')\n",
    "        plt.imsave('output_grayscale.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Grayscaled converted')\n",
    "    \n",
    "    if choice == 12 or choice == 0:\n",
    "        prd_img = convert_scale(org_img, 'sepia')\n",
    "        plt.imsave('output_sepia.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Sepia converted')\n",
    "    \n",
    "    if choice == 13 or choice == 0:\n",
    "        size = int(input('Kernel size for blurring, 3 or 5: '))\n",
    "        prd_img = convolution(org_img, GAUSSIAN_KERNEL_3 if size == 3 else GAUSSIAN_KERNEL_5)\n",
    "        plt.imsave('output_blur.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Blurred')\n",
    "    \n",
    "    if choice == 14 or choice == 0:\n",
    "        size = int(input('Kernel size for sharpenning, 3 or 5: '))\n",
    "        prd_img = convolution(org_img, SHARPEN_KERNEL_3 if size == 3 else SHARPEN_KERNEL_5)\n",
    "        plt.imsave('output_sharpen.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Sharpenned')\n",
    "    \n",
    "    if choice == 6 or choice == 0:\n",
    "        height = int(input('Crop height: '))\n",
    "        width = int(input('Crop width: '))\n",
    "        prd_img = center_crop(org_img, (height, width))\n",
    "        plt.imsave('output_center_crop.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Center cropped')\n",
    "    \n",
    "    if choice == 7 or choice == 0:\n",
    "        cx = int(input('Center coordinate\\'s x: '))\n",
    "        cy = int(input('Center coordinate\\'s y: '))\n",
    "        center = (cx, cy)\n",
    "        radius = int(input('Circle frame radius: '))\n",
    "        prd_img = circle_frame_crop(org_img, center, radius)\n",
    "        plt.imsave('output_circle_crop.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Circle cropped')\n",
    "    \n",
    "    if choice == 8 or choice == 0:\n",
    "        cx = int(input('Center coordinate\\'s x: '))\n",
    "        cy = int(input('Center coordinate\\'s y: '))\n",
    "        center = (cx, cy)\n",
    "        major_axis = int(input('Major axis length: '))\n",
    "        minor_axis = int(input('Minor axis length: '))\n",
    "        prd_img = x_ellipse_frame_crop(org_img, center, major_axis, minor_axis)\n",
    "        plt.imsave('output_x_ellipse_crop.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Crossover ellipse cropped')\n",
    "    \n",
    "    num_images = len(processed_images)\n",
    "    fig, axs = plt.subplots(num_images + 1, 1, figsize=(400, 100) if num_images != 1 else (26,14))\n",
    "    axs[0].imshow(org_img, cmap='gray')\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axs[i + 1].imshow(processed_images[i], cmap='gray')\n",
    "        axs[i + 1].set_title(processed_mechanism[i])\n",
    "        axs[i + 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
