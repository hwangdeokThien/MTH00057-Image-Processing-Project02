{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf69c2e1",
   "metadata": {},
   "source": [
    "# <center style='color: darkblue'> Project 2 report: *Image Processing* </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd0d18",
   "metadata": {},
   "source": [
    "## <font style='color: darkblue'> Table of contents\n",
    "1. [Project summary](#c1) <br>\n",
    "    1.1. [Information](#c11) <br>\n",
    "    1.2. [Introduction](#c12) <br>\n",
    "    1.3. [Completeness](#c13) <br>\n",
    "2. [Program](#c2) <br>\n",
    "    2.1. [Algorithm idea](#c21) <br>\n",
    "    2.2. [Library and function details](#c22) <br>\n",
    "3. [Test results and Comments](#c3) <br>\n",
    "    3.1. [Test results](#c31) <br>\n",
    "    3.2. [Comments](#c32) <br>\n",
    " \n",
    "[Reference](#ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1122205",
   "metadata": {},
   "source": [
    "## <font style='color: darkblue'> 1. Project summary <a id=\"c1\"></a>\n",
    "### <font style='color: darkblue'> 1.1. Information <a id=\"c11\"></a>\n",
    "**Project**\n",
    "> Image Processing\n",
    "\n",
    "**Student**\n",
    "> Full name: Huynh Duc Thien <br>\n",
    "ID: 21127693 <br>\n",
    "Contact: hdthien21@clc.fitus.edu.vn <br>\n",
    "Course: MTH00057_21CLC07 <br>\n",
    "Class: 21CLC07\n",
    "\n",
    "**Lecturers**\n",
    "> Teacher, Nguyen Dinh Thuc <br>\n",
    "Teacher, Nguyen Van Quang Huy <br>\n",
    "Teacher, Ngo Dinh Hy <br>\n",
    "Teacher, Tran Ha Son <br>\n",
    "\n",
    "### <font style='color: darkblue'> 1.2. Introduction <a id=\"c12\"></a>\n",
    "> Image processing is a fundamental discipline in the realm of computer vision and digital image analysis, aimed at enhancing, manipulating, and extracting valuable information from digital images. As the world becomes increasingly reliant on visual data, image processing techniques play a pivotal role in a wide range of applications, spanning from medical imaging and satellite imagery analysis to face recognition and artistic filters in social media applications. <br>\n",
    "> This report explores various essential image processing operations, providing insights into their functionalities and applications. Throughout this investigation, we will delve into five core techniques: image flipping, blurring, cropping, contrast and brightness adjustment, and image scaling conversion. Each of these techniques brings its unique set of advantages and applications, contributing to the versatility of image processing algorithms.\n",
    "    \n",
    "### <font style='color: darkblue'> 1.3. Completeness <a id=\"c13\"></a>\n",
    "\n",
    "| No.     | Task                                     | Completeness(%)|\n",
    "|:-------:|:-----------------------------------------|:--------------:|\n",
    "| 1       | Change brightness                        | 100            |\n",
    "| 2       | Change contrast                          | 100            |\n",
    "| 3       | Flip (horizontal and vertical)           | 100            |\n",
    "| 4       | Convert to grayscale/sepia               | 100            |\n",
    "| 5       | Crop image at center                     | 100            |\n",
    "| 6       | Crop image with circle frame             | 100            |\n",
    "| 7       | [Advanced] Crossover ellipse frame crop  | 100            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e406a",
   "metadata": {},
   "source": [
    "## <font style='color: darkblue'> 2. Program <a id=\"c2\"></a>\n",
    "### <font style='color: darkblue'> 2.1. Algorithm idea<a id=\"c21\"></a>   \n",
    "- ***Brightness change***\n",
    "\n",
    "> Changing brightness in an image involves adjusting the intensity of the pixels to make the image appear brighter or darker. In the context of using NumPy, the algorithm achieve this by performing simple arithmetic operations on the pixel values of the image. <br>\n",
    "To change the brightness of an image, addition or subtraction of a constant value applied to each pixel's intensity. This will scale the pixel values up or down, respectively, making the image appear brighter or darker.\n",
    "    \n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *change_brightness*(img, adjustment):\n",
    "        *new_img* = *img*.copy()\n",
    "        for each *pixel* in *new_img*:\n",
    "            *pixel* = *pixel* + *adjustment*\n",
    "        return *new_img*\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5fcd65",
   "metadata": {},
   "source": [
    "- ***Contrast change***\n",
    "\n",
    "> Changing contrast in an image involves adjusting the difference between the darkest and brightest pixels, which effectively changes the image's overall brightness range. Increasing contrast makes the dark pixels darker and the bright pixels brighter, enhancing the visual separation between different parts of the image. Decreasing contrast, on the other hand, compresses the range of brightness values, making the image appear more uniform and less vivid\n",
    "We can change the contrast of an image by applying a linear transformation to the pixel values. The transformation stretches or compresses the range of pixel intensities to achieve the desired contrast level.\n",
    "\n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *change_contrast*(img, adjustment):\n",
    "        *new_img* = *img*.scale()\n",
    "        for each *pixel* in *new_img*:\n",
    "            *pixel*.adjust()\n",
    "        return *new_img*\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cd52f",
   "metadata": {},
   "source": [
    "- ***Flip image***\n",
    "\n",
    "> Flipping an image is a popular operation in image processing, and it involves changing the spatial orientation of the image. There are two main types of image flipping:<br>\n",
    "\n",
    ">a. Horizontal Flip:\n",
    "In a horizontal flip, the image is flipped along a vertical axis that runs through the center of the image. As a result, the left side of the image becomes the right side, and vice versa. This operation is also known as \"left-right\" flipping.<br>\n",
    "b. Vertical Flip:\n",
    "In a vertical flip, the image is flipped along a horizontal axis that runs through the center of the image. The top part of the image becomes the bottom part, and the bottom part becomes the top part. This operation is also known as \"up-down\" flipping.\n",
    "\n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *flip*(img, axis):\n",
    "        if *axis* is horizontal:\n",
    "            for each *row* in *img*:\n",
    "                *row*.reverse()\n",
    "        else if *axis* is vertical:\n",
    "            for each *col* in *img*:\n",
    "                *col*.reverse()\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf3b26b",
   "metadata": {},
   "source": [
    "- ***Convert to grayscale***\n",
    "\n",
    ">Converting a color image to grayscale involves transforming a multi-channel (e.g., RGB) image into a single-channel grayscale image where each pixel represents the intensity of the original image. The Luminosity Method is one of the common approaches used for this conversion, aiming to preserve the perceived brightness of the colors in the original image. <br>\n",
    "The ***Luminosity Method*** takes into account the human eye's sensitivity to different colors when calculating the grayscale intensity. It gives more weight to the green channel, as the human eye is most sensitive to green, followed by the red and blue channels. The conversion formula is typically given by:\n",
    "\n",
    "   $$ Grayscale Intensity (I) = 0.3R + 0.59G + 0.11B $$\n",
    "\n",
    "> where R, G, and B are the intensity values of the red, green, and blue channels, respectively, for each pixel in the color image.\n",
    "\n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *convert_to_grayscale*(img):\n",
    "        for each *pixel* in *new_img*:\n",
    "            *pixel* = *pixel*.calculate_intensity()\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af0c8d",
   "metadata": {},
   "source": [
    "- ***Convert to sepia***\n",
    "\n",
    "> Converting an image to sepia is a classic image processing technique that gives the image an old-fashioned, warm, nostalgic tone reminiscent of early photographs. The sepia effect is achieved by manipulating the color channels of the image to create a warm, vintage look.<br>\n",
    "To convert an image to sepia, we need to modify these color channels based on specific intensity ratios. The common sepia transformation formula is given by:\n",
    "$$ Sepia R = 0.393R + 0.769G + 0.189B $$\n",
    "$$ Sepia G = 0.349R + 0.686G + 0.168B $$\n",
    "$$ Sepia B = 0.272R + 0.534G + 0.131B $$\n",
    "\n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *convert_to_sepia*(img):\n",
    "        *red* = *img*.calculate_red_sepia()\n",
    "        *green* = *img*.calculate_green_sepia()\n",
    "        *blue* = *img*.calculate_blue_sepia()\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e8108",
   "metadata": {},
   "source": [
    "- ***Blur image***  \n",
    "\n",
    ">Blurring an image using a kernel involves applying a convolution operation to the image with a predefined filter called a kernel or a mask. The kernel is a small matrix that defines how the neighboring pixels contribute to the value of the central pixel in the output image. The convolution operation calculates the weighted sum of the pixel values in the neighborhood of each pixel and replaces the central pixel's value with the result. <br>\n",
    "The blurring effect is achieved because the kernel's weights cause the sharp edges and high-frequency details in the image to be attenuated, resulting in a smoother appearance. <br>\n",
    "A common type of blurring kernel is the Gaussian kernel, which also applied in this project. The size of the kernel determines the extent of blurring.\n",
    "\n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *blur*(img, blur_kernel):\n",
    "        *height*, *width*, _ = *img*.shape\n",
    "        *kernel_height*, *kernel_width* = *blur_kernel*.shape\n",
    "        *new_img* = create_empty_image()\n",
    "        for each *pixel* in *img*:\n",
    "            *window* = extract_window(pixel)\n",
    "            *new_img*.channels = calculate_weighted(window, blur_kernel)\n",
    "        return *new_img*\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949371c",
   "metadata": {},
   "source": [
    "- ***Sharpen image***\n",
    "\n",
    ">Sharpening an image using a kernel involves enhancing the edges and high-frequency components in the image to make it appear sharper and more detailed. This process is achieved by applying a convolution operation with a predefined sharpening kernel, also known as a high-pass filter. The sharpening kernel emphasizes the differences in pixel values between neighboring pixels, thus increasing the contrast at edges and making the image look more defined.\n",
    "\n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *sharpen*(img, sharpen_kernel):\n",
    "        *height*, *width*, _ = *img*.shape\n",
    "        *kernel_height*, *kernel_width* = *sharpen_kernel*.shape\n",
    "        *new_img* = create_empty_image()\n",
    "        for each *pixel* in *img*:\n",
    "            *window* = extract_window(pixel)\n",
    "            *new_img*.channels = calculate_weighted(window, sharpen_kernel)\n",
    "        return *new_img*\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2139a",
   "metadata": {},
   "source": [
    "- ***Crop image***\n",
    "\n",
    "> Cropping an image involves selecting a region of interest (ROI) within the original image and extracting only that part as a separate image. This process effectively removes the unwanted portions of the image, creating a new image with different dimensions.<br>\n",
    "The concept of cropping an image with different frames refers to the way the region of interest is defined or the shape of the cropped area. There are several ways to specify the frame for cropping, each leading to a different visual effect. <br>\n",
    "In this project, the difference in each cropping methods is the way of applying mathematical formula to identify the mask, which selecting ROI.\n",
    "\n",
    "> Applied shape formula:<br>\n",
    "a. Circle:\n",
    "$$circle\\_mask = (y - c_y)^2 + (x - c_x)^2 \\leq r^2$$\n",
    "B. Ellipse:\n",
    "$$ellipse\\_mask = \\frac{({(x - c_x) \\cos \\alpha + (y - c_y) \\sin \\alpha})^2}{{major\\_axis^2}} + \\frac{({(x - c_x) \\sin \\alpha - (y - c_y) \\cos \\alpha})^2}{{minor\\_axis^2}} \\leq 1$$\n",
    "\n",
    "> Pseudo code:\n",
    "    <pre><code>\n",
    "    function *crop*(img, shape):\n",
    "        *shape_info* = shape.extract()\n",
    "        *mask* = calculate_mask(shape_info)\n",
    "        for each *pixel* in *img*:\n",
    "            if not in *mask*:\n",
    "                *pixel*.assign_black()\n",
    "    </code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e74958",
   "metadata": {},
   "source": [
    "### <font style='color: darkblue'> 2.2. Library and function details <a id=\"c22\"></a> \n",
    "**Library** <br>\n",
    "- *PIL Image*: read and save image data.\n",
    "- *mathplotlib.pylot*: display processed image.\n",
    "- *numpy*: apply matrix calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f75f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d67fd6",
   "metadata": {},
   "source": [
    "**Pre-defined value**\n",
    "\n",
    "Implementing kernel matrixes, including blurring gaussian kernel and sharpenning kernel in 2 different size (3x3 and 5x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214faab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel for blurring image\n",
    "GAUSSIAN_KERNEL_3 = 1/16 * np.array([[1,2,1],\n",
    "                                     [2,4,2],\n",
    "                                     [1,2,1]])\n",
    "GAUSSIAN_KERNEL_5 = 1/256 * np.array([[1, 4, 6, 4, 1],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [6, 24, 36, 24, 6],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [1, 4, 6, 4, 1]])\n",
    "# kernel for sharpening image\n",
    "SHARPEN_KERNEL_3 = np.array([[0,-1,0],\n",
    "                             [-1,5,-1],\n",
    "                             [0,-1,0]])\n",
    "SHARPEN_KERNEL_5 = -1/256 * np.array([[1, 4, 6, 4, 1],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [6, 24, -476, 24, 6],\n",
    "                                      [4, 16, 24, 16, 4],\n",
    "                                      [1, 4, 6, 4, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9551303",
   "metadata": {},
   "source": [
    "**Auxilary function**\n",
    "- `menu_choice()` Showing menu, providing choices for users, taking no input, and returning user's choice for processing purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b405d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu_choice():\n",
    "    print('1. Change brightness')\n",
    "    print('2. Change contrast')\n",
    "    print('3. Flip image')\n",
    "    print('4. Convert to grayscale/sepia')\n",
    "    print('5. Blur/sharpen')\n",
    "    print('6. Center crop')\n",
    "    print('7. Circle frame crop')\n",
    "    print('8. Double elip frame crop')\n",
    "    print('0. Change all')\n",
    "    choice = int(input('Your choice: '))\n",
    "    \n",
    "    if choice == 3:\n",
    "        print('\\n1. Flip vertically')\n",
    "        print('2. Flip horizontally')\n",
    "        sub_choice = int(input('Your choice: '))\n",
    "        choice = 9 if sub_choice == 1 else 10\n",
    "    elif choice == 4:\n",
    "        print('\\n1. Grayscale')\n",
    "        print('2. Sepia')\n",
    "        sub_choice = int(input('Your choice: '))\n",
    "        choice = 11 if sub_choice == 1 else 12\n",
    "    elif choice == 5:\n",
    "        print('\\n1. Blur')\n",
    "        print('2. Sharpen')\n",
    "        sub_choice = int(input('Your choice: '))\n",
    "        choice = 13 if sub_choice == 1 else 14\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f610c3",
   "metadata": {},
   "source": [
    "**Processing image functions**\n",
    "\n",
    "- `change_brightness()` function designed to adjust the brightness of an input image. This function takes two arguments: `img` representing the input image as a NumPy array, and `adjustment` a numerical value that determines the brightness level to be applied, the positive value is for increase brightness, vice versa. The function processes the image by adding the specified adjustment value to each pixel's intensity. The function then returns a NumPy array representing processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a98735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brightness(img, adjustment):\n",
    "    adjusted_img = img.astype(np.int32) + adjustment\n",
    "    adjusted_img = np.clip(adjusted_img, 0, 255)\n",
    "    return adjusted_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd081c",
   "metadata": {},
   "source": [
    "- `change_contrast()` function designed to adjust the contrast of an input image. This function takes two arguments: `img` representing the input image as a NumPy array, a numerical value that determines the level of contrast to be applied. The function processes the image by altering the intensity distribution to enhance or reduce the image's contrast. The function then returns a NumPy array representing processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98737b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_contrast(img, adjustment):\n",
    "    float_img = img.astype(np.float32) / 255.0\n",
    "    adjusted_channels = np.clip((float_img - 0.5) * adjustment + 0.5, 0, 1)\n",
    "    adjusted_img = (adjusted_channels * 255).astype(np.uint8)\n",
    "    return adjusted_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2896113",
   "metadata": {},
   "source": [
    "- `flip()` function designed to adjust the contrast of an input image. This function takes two arguments: `img` representing the input image as a NumPy array, and `adjustment` a string specifying the flip direction. The function processes the image by reversing the order of pixels along the specified axis which is either 'horizontal' or 'vertical'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e16735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(img, axis='horizontal'):\n",
    "    if axis == 'horizontal':\n",
    "        return img[:, ::-1, :]\n",
    "    else:\n",
    "        return img[::-1, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02246ba8",
   "metadata": {},
   "source": [
    "- `conver_scale()` function designed to convert an input image to a different color scale, such as grayscale or sepia. This function takes two arguments: `img` representing the input image as a NumPy array, and `method` a string specifying the color scale conversion method. The function processes the image according to the specified method and returns the image in the desired color scale. The function then returns a NumPy array representing processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_scale(img, method='sepia'):\n",
    "    if method == 'grayscale':\n",
    "        adjusted_img = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    else:\n",
    "        sepia_mtx = np.array([[0.393, 0.769, 0.189],\n",
    "                              [0.349, 0.686, 0.168],\n",
    "                              [0.272, 0.534, 0.131]])\n",
    "        adjusted_img = np.clip(np.dot(img, sepia_mtx.T), 0, 255)\n",
    "    \n",
    "    adjusted_img = np.round(adjusted_img).astype(np.uint8)\n",
    "    return adjusted_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010dd722",
   "metadata": {},
   "source": [
    "- `convolution()` function designed to apply a 2D convolution operation to an input image using a given kernel. This function takes two arguments: `img` representing the input image as a NumPy array, and `kernel` representing the convolution kernel as a 2D NumPy array. The function processes the image by convolving the kernel with each pixel neighborhood to produce a new image with the applied effect which is either blurring or sharpenning. The function then returns a NumPy array representing processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, kernel):\n",
    "    height, width, _ = img.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    adjusted_img = np.zeros((height, width, 3), dtype=float) \n",
    "    \n",
    "    for i in range(kernel_height//2, height-kernel_height//2-1):\n",
    "        for j in range(kernel_width//2, width-kernel_width//2-1):\n",
    "            window = img[i-kernel_height//2 : i+kernel_height//2+1,j-kernel_width//2 : j+kernel_width//2+1]\n",
    "            adjusted_img[i, j] = [int((window[:,:,k] * kernel).sum()) for k in range(3)]\n",
    "      \n",
    "    adjusted_img = np.clip(adjusted_img, 0, 255)\n",
    "    return adjusted_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d7d9e",
   "metadata": {},
   "source": [
    "- `center_crop()` function designed to perform a centered cropping operation on an input image. This function takes two arguments: `img` representing the input image as a NumPy array, and `crop_shape` a tuple specifying the dimensions (height and width) of the desired cropped region. The function processes the image by extracting a centered rectangular region with the specified dimensions. The function then returns a NumPy array representing processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463fd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, crop_shape):\n",
    "    height, width, _ = img.shape\n",
    "    crop_height, crop_width = crop_shape\n",
    "\n",
    "    start_height = (height - crop_height) // 2\n",
    "    start_width = (width - crop_width) // 2\n",
    "\n",
    "    end_height = start_height + crop_height\n",
    "    end_width = start_width + crop_width\n",
    "\n",
    "    cropped_img = img[start_height:end_height, start_width:end_width]\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d529ea",
   "metadata": {},
   "source": [
    "- `circle_frame_crop()` function is a Python implementation designed to perform a circular frame cropping operation on an input image. This function takes three arguments: `img` representing the input image as a NumPy array, `center` a tuple specifying the coordinates (y, x) of the circle's center, and `radius` a numerical value representing the circle's radius. The function processes the image by extracting a circular region while preserving the frame or boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_frame_crop(img, center, radius):\n",
    "    yy, xx = np.ogrid[:img.shape[0], :img.shape[1]]\n",
    "    cy, cx = center\n",
    "    \n",
    "    circle_mask = (yy - cy)**2 + (xx - cx)**2 <= radius**2\n",
    "\n",
    "    cropped_img = np.copy(img)\n",
    "    cropped_img[~circle_mask] = 0\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54ccdc",
   "metadata": {},
   "source": [
    "- The functions `ellipse_frame_crop()` and `x_ellipse_frame_crop()` are designed to perform ellipse frame cropping operations on an input image. This function takes three arguments: `img` representing the input image as a NumPy array, `center` a tuple specifying the coordinates (y, x) of the circle's center, `major_axis` is the length of the major axis of the ellipse, `minor_axis` is the length of the minor axis of the ellipse, and `deg_angle` is the angle (in degrees) of the major axis with respect to the horizontal axis. These functions extract elliptical regions while preserving the frame or boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a757a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse_frame_crop(img, center, major_axis, minor_axis, deg_angle):\n",
    "    yy, xx = np.ogrid[:img.shape[0], :img.shape[1]]\n",
    "    cy, cx = center\n",
    "    rad_angle = np.deg2rad(deg_angle)\n",
    "\n",
    "    ellipse_mask = ((xx - cx) * np.cos(rad_angle) + (yy - cy) * np.sin(rad_angle))**2 / (major_axis**2) + ((xx - cx) * np.sin(rad_angle) - (yy - cy) * np.cos(rad_angle))**2 / (minor_axis**2) <= 1\n",
    "\n",
    "    cropped_img = np.copy(img)\n",
    "    cropped_img[~ellipse_mask] = 0\n",
    "\n",
    "    return cropped_img\n",
    "\n",
    "def x_ellipse_frame_crop(img, center, major_axis, minor_axis):\n",
    "    yy, xx = np.ogrid[:img.shape[0], :img.shape[1]]\n",
    "    cy, cx = center\n",
    "    \n",
    "    deg_angle = 45.0\n",
    "    rad_angle = np.deg2rad(deg_angle)\n",
    "    ellipse_mask_1 = ((xx - cx) * np.cos(rad_angle) + (yy - cy) * np.sin(rad_angle))**2 / (major_axis**2) + ((xx - cx) * np.sin(rad_angle) - (yy - cy) * np.cos(rad_angle))**2 / (minor_axis**2) <= 1\n",
    "\n",
    "    deg_angle = 135.0\n",
    "    rad_angle = np.deg2rad(deg_angle)\n",
    "    ellipse_mask_2 = ((xx - cx) * np.cos(rad_angle) + (yy - cy) * np.sin(rad_angle))**2 / (major_axis**2) + ((xx - cx) * np.sin(rad_angle) - (yy - cy) * np.cos(rad_angle))**2 / (minor_axis**2) <= 1\n",
    "    \n",
    "    cropped_img = np.copy(img)\n",
    "    cropped_img[~(ellipse_mask_1 | ellipse_mask_2)] = 0\n",
    "    \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34489e96",
   "metadata": {},
   "source": [
    "**Main function** <br>\n",
    "The main function provides an simple console UI for inputs and outputs. <br>\n",
    "In this program, the user has to input the right image-path, if not, no action will be maded. The image data is read by using `Image` in `PIL` library, i.e, reading pixel colors and indexs. The received data will be converted to a NumPY array to facilitate image processing. All input and processed images then will be displayed for comparisons (using `pylot` of `matplotlib` library). The output images will be automaticly save as png file to the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309848d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    img_path = str(input('Path to image: '))\n",
    "    try:\n",
    "        image = Image.open(img_path)\n",
    "    except:\n",
    "        print('can not open image!')\n",
    "        return\n",
    "    \n",
    "    org_img = np.array(image)\n",
    "    \n",
    "    choice = menu_choice()\n",
    "    processed_images = []\n",
    "    processed_mechanism = []\n",
    "    \n",
    "    if choice == 1 or choice == 0:\n",
    "        adjustment = int(input('Input brightness change: '))\n",
    "        prd_img = change_brightness(org_img.copy(), adjustment)\n",
    "        plt.imsave('output_brightness_change.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Brightness changed')\n",
    "        \n",
    "    if choice == 2 or choice == 0:\n",
    "        adjustment = input('Input contrast change: ')\n",
    "        prd_img = change_contrast(org_img, float(adjustment))\n",
    "        plt.imsave('output_contrast_change.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Contrast changed')\n",
    "    \n",
    "    if choice == 9 or choice == 0:\n",
    "        prd_img = flip(org_img, 'vertical')\n",
    "        plt.imsave('output_vertical_flip.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Vertical flip')\n",
    "    \n",
    "    if choice == 10 or choice == 0:\n",
    "        prd_img = flip(org_img, 'horizontal')\n",
    "        plt.imsave('output_horizontal_flip.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Horizontal flip')\n",
    "    \n",
    "    if choice == 11 or choice == 0:\n",
    "        prd_img = convert_scale(org_img, 'grayscale')\n",
    "        plt.imsave('output_grayscale.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Grayscaled converted')\n",
    "    \n",
    "    if choice == 12 or choice == 0:\n",
    "        prd_img = convert_scale(org_img, 'sepia')\n",
    "        plt.imsave('output_sepia.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Sepia converted')\n",
    "    \n",
    "    if choice == 13 or choice == 0:\n",
    "        size = int(input('Kernel size for blurring, 3 or 5: '))\n",
    "        prd_img = convolution(org_img, GAUSSIAN_KERNEL_3 if size == 3 else GAUSSIAN_KERNEL_5)\n",
    "        plt.imsave('output_blur.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Blurred')\n",
    "    \n",
    "    if choice == 14 or choice == 0:\n",
    "        size = int(input('Kernel size for sharpenning, 3 or 5: '))\n",
    "        prd_img = convolution(org_img, SHARPEN_KERNEL_3 if size == 3 else SHARPEN_KERNEL_5)\n",
    "        plt.imsave('output_sharpen.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Sharpenned')\n",
    "    \n",
    "    if choice == 6 or choice == 0:\n",
    "        height = int(input('Crop height: '))\n",
    "        width = int(input('Crop width: '))\n",
    "        prd_img = center_crop(org_img, (height, width))\n",
    "        plt.imsave('output_center_crop.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Center cropped')\n",
    "    \n",
    "    if choice == 7 or choice == 0:\n",
    "        cx = int(input('Center coordinate\\'s x: '))\n",
    "        cy = int(input('Center coordinate\\'s y: '))\n",
    "        center = (cx, cy)\n",
    "        radius = int(input('Circle frame radius: '))\n",
    "        prd_img = circle_frame_crop(org_img, center, radius)\n",
    "        plt.imsave('output_circle_crop.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Circle cropped')\n",
    "    \n",
    "    if choice == 8 or choice == 0:\n",
    "        cx = int(input('Center coordinate\\'s x: '))\n",
    "        cy = int(input('Center coordinate\\'s y: '))\n",
    "        center = (cx, cy)\n",
    "        major_axis = int(input('Major axis length: '))\n",
    "        minor_axis = int(input('Minor axis length: '))\n",
    "        prd_img = x_ellipse_frame_crop(org_img, center, major_axis, minor_axis)\n",
    "        plt.imsave('output_x_ellipse_crop.png', prd_img, cmap='gray')\n",
    "        processed_images.append(prd_img)\n",
    "        processed_mechanism.append('Crossover ellipse cropped')\n",
    "    \n",
    "    num_images = len(processed_images)\n",
    "    fig, axs = plt.subplots(num_images + 1, 1, figsize=(400, 100) if num_images != 1 else (26,14))\n",
    "    axs[0].imshow(org_img, cmap='gray')\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axs[i + 1].imshow(processed_images[i], cmap='gray')\n",
    "        axs[i + 1].set_title(processed_mechanism[i])\n",
    "        axs[i + 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad8104",
   "metadata": {},
   "source": [
    "## <font style='color: darkblue'> 3. Test results and Comments <a id=\"c3\"> </a>\n",
    "### <font style='color: darkblue'> 3.1. Test results<a id=\"c31\">\n",
    "\n",
    "- Original image: \n",
    "    <img src=\"https://drive.google.com/uc?id=1wLOcJVzRt50kUQDPOEwAX3rBphomJ57X\" alt=\"tree.png\" width=\"800px\" >\n",
    "<br>\n",
    "\n",
    "- Result images:\n",
    "    - Brightness changed:\n",
    "    <img src=\"https://drive.google.com/uc?id=10Wg61K2DeYzm7WCLkET4bkyBh59lC8_6\" alt=\"tree_brightness_change.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Contrast changed:\n",
    "    <img src=\"https://drive.google.com/uc?id=1sO4MSbbwuVcpa5ousVydCVKAKwCemkQj\" alt=\"tree_contrast_change.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Flip horizontally:\n",
    "    <img src=\"https://drive.google.com/uc?id=1Y6N_xlMDhW2wHNgSRtMZ_rgIkabKKzHT\" alt=\"tree_horizontal_flip.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Flip vertically:\n",
    "    <img src=\"https://drive.google.com/uc?id=1Yj3Zp1hBQUvJYMLI6P9YyW4l5r0kUDV5\" alt=\"tree_vertical_flip.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Convert to grayscale:\n",
    "    <img src=\"https://drive.google.com/uc?id=1TlQs6VQvIVURgKcnv3EJu-d165qC3YNs\" alt=\"tree_grayscale.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Convert to sepia:\n",
    "    <img src=\"https://drive.google.com/uc?id=1-OYSYpoPV5liB7RCthq-sZm8n0b8YrHN\" alt=\"tree_sepia.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Blured:\n",
    "    <img src=\"https://drive.google.com/uc?id=1yQbpgy8JRjtqVvTKIJdEVOHsyZjzKqkv\" alt=\"tree_blur.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Sharpened:\n",
    "    <img src=\"https://drive.google.com/uc?id=1LrfZ0wQacmnDQybN0ZYliTBDWxbKmqhn\" alt=\"tree_sharpen.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Center cropped:\n",
    "    <img src=\"https://drive.google.com/uc?id=14pGCggqQ_gIYOM-28X5tqJC19F2q6gfx\" alt=\"tree_center_crop.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Circle cropped:\n",
    "    <img src=\"https://drive.google.com/uc?id=1IM6wXv974K77FWtFyL9LS4kP6Ba3CwiB\" alt=\"tree_circle_crop.png\" width=\"800px\" >\n",
    "    <br>\n",
    "    - Crossover ellipse cropped:\n",
    "    <img src=\"https://drive.google.com/uc?id=1TWuk1EVkAl6J3F-IPRQ8sYomxYDZ7Uti\" alt=\"tree_x_ellipse_crop.png\" width=\"800px\" >\n",
    "    <br>\n",
    "\n",
    "***image detail*** <br>\n",
    "> [original_image](https://drive.google.com/uc?id=1wLOcJVzRt50kUQDPOEwAX3rBphomJ57X) <br>\n",
    "[brightness_change](https://drive.google.com/uc?id=10Wg61K2DeYzm7WCLkET4bkyBh59lC8_6)<br>\n",
    "[contrast_change](https://drive.google.com/uc?id=1sO4MSbbwuVcpa5ousVydCVKAKwCemkQj)<br>\n",
    "[horizontal_flip](https://drive.google.com/uc?id=1Y6N_xlMDhW2wHNgSRtMZ_rgIkabKKzHT)<br>\n",
    "[vertical_flip](https://drive.google.com/uc?id=1Yj3Zp1hBQUvJYMLI6P9YyW4l5r0kUDV5)<br>\n",
    "[grayscale](https://drive.google.com/uc?id=1TlQs6VQvIVURgKcnv3EJu-d165qC3YNs)<br>\n",
    "[sepia](https://drive.google.com/uc?id=1-OYSYpoPV5liB7RCthq-sZm8n0b8YrHN)<br>\n",
    "[blur](https://drive.google.com/uc?id=1yQbpgy8JRjtqVvTKIJdEVOHsyZjzKqkv)<br>\n",
    "[sharpen](https://drive.google.com/uc?id=1LrfZ0wQacmnDQybN0ZYliTBDWxbKmqhn)<br>\n",
    "[center_crop](https://drive.google.com/uc?id=14pGCggqQ_gIYOM-28X5tqJC19F2q6gfx)<br>\n",
    "[circle_crop](https://drive.google.com/uc?id=1IM6wXv974K77FWtFyL9LS4kP6Ba3CwiB)<br>\n",
    "[crossover_ellipse_crop](https://drive.google.com/uc?id=1TWuk1EVkAl6J3F-IPRQ8sYomxYDZ7Uti)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd82f8",
   "metadata": {},
   "source": [
    "### <font style='color: darkblue'> 3.2. Comments<a id=\"c32\">\n",
    "> This project provides a more specific perspective on image processing, including common tools such as brightness and contrast adjustment, grayscale and sepia conversion, image flipping, and image cropping. Applying these techniques in this project offers valuable experience in using libraries and manipulating RGB image matrices. The output results demonstrate excellent and feasible outcomes, and the program can be further customized to meet different requirements. Mathematical formulas related to image processing are also applied to achieve the best results.\n",
    "\n",
    "> Image processing can be applied for various educational and social purposes, such as enhancing image quality, restoring old photos with historical and scientific value, as well as serving as a useful learning tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4d8d5",
   "metadata": {},
   "source": [
    "## <font style='color: darkblue'> Reference <a id=\"ref\"> </a>\n",
    "**Syntax**\n",
    "> [1] [Markdown paragraph syntax](https://medium.com/game-of-data/12-things-to-know-about-jupyter-notebook-markdown-3f6cef811707) <br>\n",
    "[2] [Mark down math formula syntax](https://jupyterbook.org/en/stable/content/math.html) <br>\n",
    "\n",
    "**Algorithm**\n",
    "> [3] [Converting RGB to grayscale image](https://www.baeldung.com/cs/convert-rgb-to-grayscale) <br>\n",
    "[4] [Convert to sepia image](https://dyclassroom.com/image-processing-project/how-to-convert-a-color-image-into-sepia-image) <br>\n",
    "[5] [Kernel (image processing)](https://en.wikipedia.org/wiki/Kernel_(image_processing)) <br>\n",
    "\n",
    "**Library**\n",
    "> [6] [Image PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html) <br>\n",
    "[7] [mathplotlib.pylot](https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html) <br>\n",
    "[8] [numpy](https://numpy.org/) <br>\n",
    "    \n",
    "    \n",
    "    \n",
    "<center>-The end-</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
